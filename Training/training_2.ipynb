{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values removed from the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Remove negative values from the dataset\n",
    "for column in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    df = df[df[column] >= 0]\n",
    "\n",
    "print('Negative values removed from the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaled_features = scaler.fit_transform(df[['month', 'day', 'time', 'humidity', 'tempC']])\n",
    "# print(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month       day      time  humidity  tempC\n",
      "0  0.083333  0.032258  0.000000      0.74   0.36\n",
      "1  0.083333  0.032258  0.041667      0.78   0.36\n",
      "2  0.083333  0.032258  0.083333      0.82   0.34\n",
      "3  0.083333  0.032258  0.125000      0.85   0.34\n",
      "4  0.083333  0.032258  0.166667      0.83   0.34\n"
     ]
    }
   ],
   "source": [
    "scaled_features = pd.DataFrame()\n",
    "scaled_features['month'] = df['month'] / 12\n",
    "scaled_features['day'] = df['day'] / 31\n",
    "scaled_features['time'] = df['time'] / 24\n",
    "scaled_features['humidity'] = df['humidity'] / 100\n",
    "scaled_features['tempC'] = df['tempC'] / 50\n",
    "print(scaled_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_features\n",
    "y = df['fan_speed'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2), input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  # Softmax activation for multi-class classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 2s 10ms/step - loss: 1.4926 - accuracy: 0.3909 - val_loss: 1.3448 - val_accuracy: 0.4196\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2631 - accuracy: 0.4414 - val_loss: 1.1522 - val_accuracy: 0.4893\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1128 - accuracy: 0.5079 - val_loss: 1.0398 - val_accuracy: 0.6003\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.0061 - accuracy: 0.5684 - val_loss: 0.9434 - val_accuracy: 0.5960\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9308 - accuracy: 0.5969 - val_loss: 0.8849 - val_accuracy: 0.6565\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.8714 - accuracy: 0.6257 - val_loss: 0.8419 - val_accuracy: 0.6366\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.8127 - accuracy: 0.6534 - val_loss: 0.7646 - val_accuracy: 0.6906\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.7632 - accuracy: 0.6796 - val_loss: 0.7334 - val_accuracy: 0.6814\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.6983 - val_loss: 0.6816 - val_accuracy: 0.7233\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.7212 - val_loss: 0.6641 - val_accuracy: 0.6984\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6522 - accuracy: 0.7346 - val_loss: 0.6205 - val_accuracy: 0.7418\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.6274 - accuracy: 0.7422 - val_loss: 0.5960 - val_accuracy: 0.7276\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5996 - accuracy: 0.7650 - val_loss: 0.5721 - val_accuracy: 0.7646\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7717 - val_loss: 0.5584 - val_accuracy: 0.7909\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7849 - val_loss: 0.5505 - val_accuracy: 0.7717\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5572 - accuracy: 0.7844 - val_loss: 0.5309 - val_accuracy: 0.7817\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5356 - accuracy: 0.7919 - val_loss: 0.5146 - val_accuracy: 0.7916\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.8064 - val_loss: 0.5115 - val_accuracy: 0.7945\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.8027 - val_loss: 0.5221 - val_accuracy: 0.7852\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.8107 - val_loss: 0.4885 - val_accuracy: 0.8129\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4968 - accuracy: 0.8144 - val_loss: 0.4823 - val_accuracy: 0.8158\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.8207 - val_loss: 0.4626 - val_accuracy: 0.8215\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.8192 - val_loss: 0.4693 - val_accuracy: 0.8222\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.8301 - val_loss: 0.4557 - val_accuracy: 0.8378\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8267 - val_loss: 0.4519 - val_accuracy: 0.8329\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.8349 - val_loss: 0.4459 - val_accuracy: 0.8407\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8374 - val_loss: 0.4369 - val_accuracy: 0.8286\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8378 - val_loss: 0.4344 - val_accuracy: 0.8428\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.8404 - val_loss: 0.4229 - val_accuracy: 0.8364\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.8410 - val_loss: 0.4224 - val_accuracy: 0.8435\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8420 - val_loss: 0.4458 - val_accuracy: 0.8257\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4202 - accuracy: 0.8488 - val_loss: 0.4098 - val_accuracy: 0.8542\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8495 - val_loss: 0.4048 - val_accuracy: 0.8421\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4117 - accuracy: 0.8509 - val_loss: 0.4037 - val_accuracy: 0.8549\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8555 - val_loss: 0.4068 - val_accuracy: 0.8514\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8566 - val_loss: 0.3950 - val_accuracy: 0.8343\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8589 - val_loss: 0.4038 - val_accuracy: 0.8428\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8523 - val_loss: 0.3841 - val_accuracy: 0.8492\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3884 - accuracy: 0.8630 - val_loss: 0.3817 - val_accuracy: 0.8570\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.8564 - val_loss: 0.4065 - val_accuracy: 0.8414\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8612 - val_loss: 0.3745 - val_accuracy: 0.8599\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8632 - val_loss: 0.3708 - val_accuracy: 0.8506\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3784 - accuracy: 0.8635 - val_loss: 0.3685 - val_accuracy: 0.8706\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3712 - accuracy: 0.8650 - val_loss: 0.3641 - val_accuracy: 0.8585\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8691 - val_loss: 0.3608 - val_accuracy: 0.8606\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3638 - accuracy: 0.8694 - val_loss: 0.3699 - val_accuracy: 0.8642\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3639 - accuracy: 0.8673 - val_loss: 0.3538 - val_accuracy: 0.8784\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8641 - val_loss: 0.3594 - val_accuracy: 0.8720\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3542 - accuracy: 0.8684 - val_loss: 0.3773 - val_accuracy: 0.8471\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8616 - val_loss: 0.3407 - val_accuracy: 0.8755\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3540 - accuracy: 0.8671 - val_loss: 0.3436 - val_accuracy: 0.8677\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3451 - accuracy: 0.8717 - val_loss: 0.3580 - val_accuracy: 0.8734\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3493 - accuracy: 0.8714 - val_loss: 0.3486 - val_accuracy: 0.8528\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3409 - accuracy: 0.8755 - val_loss: 0.3421 - val_accuracy: 0.8741\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.8748 - val_loss: 0.3336 - val_accuracy: 0.8670\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8724 - val_loss: 0.3241 - val_accuracy: 0.8748\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3341 - accuracy: 0.8783 - val_loss: 0.3404 - val_accuracy: 0.8556\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.3321 - accuracy: 0.8781 - val_loss: 0.3320 - val_accuracy: 0.8698\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3261 - accuracy: 0.8755 - val_loss: 0.3241 - val_accuracy: 0.8713\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8838 - val_loss: 0.3166 - val_accuracy: 0.8741\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.8737 - val_loss: 0.3147 - val_accuracy: 0.8741\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3217 - accuracy: 0.8758 - val_loss: 0.3166 - val_accuracy: 0.8734\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3174 - accuracy: 0.8804 - val_loss: 0.3168 - val_accuracy: 0.8677\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8819 - val_loss: 0.3065 - val_accuracy: 0.8834\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3083 - accuracy: 0.8844 - val_loss: 0.3127 - val_accuracy: 0.8642\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3137 - accuracy: 0.8799 - val_loss: 0.3087 - val_accuracy: 0.8755\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8819 - val_loss: 0.3236 - val_accuracy: 0.8642\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.8813 - val_loss: 0.3019 - val_accuracy: 0.8755\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3062 - accuracy: 0.8820 - val_loss: 0.3036 - val_accuracy: 0.8770\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3019 - accuracy: 0.8815 - val_loss: 0.3092 - val_accuracy: 0.8798\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.3028 - accuracy: 0.8829 - val_loss: 0.3285 - val_accuracy: 0.8578\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2974 - accuracy: 0.8847 - val_loss: 0.2931 - val_accuracy: 0.8855\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2984 - accuracy: 0.8824 - val_loss: 0.2950 - val_accuracy: 0.8869\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.8833 - val_loss: 0.2863 - val_accuracy: 0.8876\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.8838 - val_loss: 0.2893 - val_accuracy: 0.8869\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8922 - val_loss: 0.2890 - val_accuracy: 0.8890\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2884 - accuracy: 0.8883 - val_loss: 0.2915 - val_accuracy: 0.8834\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2861 - accuracy: 0.8897 - val_loss: 0.2888 - val_accuracy: 0.8770\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2952 - accuracy: 0.8840 - val_loss: 0.3050 - val_accuracy: 0.8649\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8901 - val_loss: 0.2784 - val_accuracy: 0.8848\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2847 - accuracy: 0.8865 - val_loss: 0.2829 - val_accuracy: 0.8919\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2780 - accuracy: 0.8909 - val_loss: 0.2785 - val_accuracy: 0.8855\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8904 - val_loss: 0.2770 - val_accuracy: 0.8905\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2751 - accuracy: 0.8934 - val_loss: 0.2754 - val_accuracy: 0.8898\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2754 - accuracy: 0.8940 - val_loss: 0.3092 - val_accuracy: 0.8663\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.8899 - val_loss: 0.2785 - val_accuracy: 0.8898\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.8931 - val_loss: 0.2783 - val_accuracy: 0.8855\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2742 - accuracy: 0.8879 - val_loss: 0.2920 - val_accuracy: 0.8741\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.8893 - val_loss: 0.3119 - val_accuracy: 0.8556\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2896 - accuracy: 0.8808 - val_loss: 0.2743 - val_accuracy: 0.8784\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2758 - accuracy: 0.8826 - val_loss: 0.2716 - val_accuracy: 0.8876\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2650 - accuracy: 0.8956 - val_loss: 0.2729 - val_accuracy: 0.8869\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2647 - accuracy: 0.8929 - val_loss: 0.2801 - val_accuracy: 0.8841\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.8954 - val_loss: 0.2854 - val_accuracy: 0.8791\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8901 - val_loss: 0.2972 - val_accuracy: 0.8826\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2664 - accuracy: 0.8945 - val_loss: 0.2662 - val_accuracy: 0.8912\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2669 - accuracy: 0.8890 - val_loss: 0.2696 - val_accuracy: 0.8876\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.8876 - val_loss: 0.2717 - val_accuracy: 0.8876\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.8941 - val_loss: 0.2813 - val_accuracy: 0.8812\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.8906 - val_loss: 0.2621 - val_accuracy: 0.8883\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=90, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step\n",
      "Test Accuracy (Threshold): 0.9021058622652248\n"
     ]
    }
   ],
   "source": [
    "# Convert true classes to one-hot encoding\n",
    "true_classes_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=6)\n",
    "predicted_classes = model.predict(X_test)\n",
    "# print(predicted_classes)\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(np.argmax(predicted_classes, axis=1) == np.argmax(true_classes_one_hot, axis=1))\n",
    "print(\"Test Accuracy (Threshold):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

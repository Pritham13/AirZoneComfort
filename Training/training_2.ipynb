{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values removed from the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Remove negative values from the dataset\n",
    "for column in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    df = df[df[column] >= 0]\n",
    "\n",
    "print('Negative values removed from the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(df[['month', 'day', 'time', 'humidity', 'tempC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_features\n",
    "y = df['fan_speed'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu', input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  # Softmax activation for multi-class classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.8998 - val_loss: 0.2317 - val_accuracy: 0.8890\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.8981 - val_loss: 0.2415 - val_accuracy: 0.8855\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9011 - val_loss: 0.2359 - val_accuracy: 0.8933\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.8986 - val_loss: 0.2350 - val_accuracy: 0.8926\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.8970 - val_loss: 0.2371 - val_accuracy: 0.8883\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9020 - val_loss: 0.2444 - val_accuracy: 0.8826\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9014 - val_loss: 0.2321 - val_accuracy: 0.8919\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.9007 - val_loss: 0.2375 - val_accuracy: 0.8883\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2233 - accuracy: 0.9022 - val_loss: 0.2588 - val_accuracy: 0.8848\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.9000 - val_loss: 0.2490 - val_accuracy: 0.8826\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9022 - val_loss: 0.2424 - val_accuracy: 0.8905\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.9007 - val_loss: 0.2305 - val_accuracy: 0.8933\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.9018 - val_loss: 0.2384 - val_accuracy: 0.8898\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.9027 - val_loss: 0.2577 - val_accuracy: 0.8812\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.9000 - val_loss: 0.2357 - val_accuracy: 0.8933\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.8988 - val_loss: 0.2456 - val_accuracy: 0.8841\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2268 - accuracy: 0.8975 - val_loss: 0.2450 - val_accuracy: 0.8905\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.9043 - val_loss: 0.2520 - val_accuracy: 0.8834\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.8998 - val_loss: 0.2336 - val_accuracy: 0.8926\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2272 - accuracy: 0.8988 - val_loss: 0.2457 - val_accuracy: 0.8926\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.9013 - val_loss: 0.2332 - val_accuracy: 0.8876\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.8998 - val_loss: 0.2471 - val_accuracy: 0.8890\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.9025 - val_loss: 0.2323 - val_accuracy: 0.8898\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9018 - val_loss: 0.2449 - val_accuracy: 0.8862\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.8998 - val_loss: 0.2454 - val_accuracy: 0.8834\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.9004 - val_loss: 0.2463 - val_accuracy: 0.8826\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.8988 - val_loss: 0.2329 - val_accuracy: 0.8898\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.9002 - val_loss: 0.2383 - val_accuracy: 0.8912\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9004 - val_loss: 0.2397 - val_accuracy: 0.8890\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.9004 - val_loss: 0.2352 - val_accuracy: 0.8890\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.9029 - val_loss: 0.2298 - val_accuracy: 0.8898\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2202 - accuracy: 0.9032 - val_loss: 0.2296 - val_accuracy: 0.8947\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.9020 - val_loss: 0.2538 - val_accuracy: 0.8819\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.8997 - val_loss: 0.2406 - val_accuracy: 0.8954\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.9057 - val_loss: 0.2316 - val_accuracy: 0.8912\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.9006 - val_loss: 0.2373 - val_accuracy: 0.8869\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.9007 - val_loss: 0.2391 - val_accuracy: 0.8905\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9038 - val_loss: 0.2429 - val_accuracy: 0.8912\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.9022 - val_loss: 0.2368 - val_accuracy: 0.8876\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.8995 - val_loss: 0.2313 - val_accuracy: 0.8898\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.9022 - val_loss: 0.2347 - val_accuracy: 0.8883\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.9029 - val_loss: 0.2431 - val_accuracy: 0.8848\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9036 - val_loss: 0.2361 - val_accuracy: 0.8919\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9007 - val_loss: 0.2347 - val_accuracy: 0.8862\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2255 - accuracy: 0.9000 - val_loss: 0.2361 - val_accuracy: 0.8883\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.9013 - val_loss: 0.2402 - val_accuracy: 0.8848\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9039 - val_loss: 0.2296 - val_accuracy: 0.8962\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9002 - val_loss: 0.2601 - val_accuracy: 0.8841\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2262 - accuracy: 0.9013 - val_loss: 0.2407 - val_accuracy: 0.8848\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9045 - val_loss: 0.2293 - val_accuracy: 0.8905\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9030 - val_loss: 0.2389 - val_accuracy: 0.8869\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.9004 - val_loss: 0.2328 - val_accuracy: 0.8933\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.9057 - val_loss: 0.2309 - val_accuracy: 0.8912\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.9041 - val_loss: 0.2338 - val_accuracy: 0.8926\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.9043 - val_loss: 0.2405 - val_accuracy: 0.8905\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.9025 - val_loss: 0.2316 - val_accuracy: 0.8954\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2281 - accuracy: 0.9007 - val_loss: 0.2367 - val_accuracy: 0.8869\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2204 - accuracy: 0.9020 - val_loss: 0.2318 - val_accuracy: 0.8905\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9038 - val_loss: 0.2368 - val_accuracy: 0.8883\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.9007 - val_loss: 0.2354 - val_accuracy: 0.8869\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.8993 - val_loss: 0.2417 - val_accuracy: 0.8933\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.9002 - val_loss: 0.2321 - val_accuracy: 0.8862\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9032 - val_loss: 0.2412 - val_accuracy: 0.8940\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.9034 - val_loss: 0.2468 - val_accuracy: 0.8826\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.9057 - val_loss: 0.2329 - val_accuracy: 0.8905\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.9032 - val_loss: 0.2506 - val_accuracy: 0.8869\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.9045 - val_loss: 0.2272 - val_accuracy: 0.8933\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.9039 - val_loss: 0.2307 - val_accuracy: 0.8947\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.9032 - val_loss: 0.2321 - val_accuracy: 0.8890\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.9013 - val_loss: 0.2313 - val_accuracy: 0.8898\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.9020 - val_loss: 0.2300 - val_accuracy: 0.8890\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9068 - val_loss: 0.2324 - val_accuracy: 0.8940\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.9073 - val_loss: 0.2279 - val_accuracy: 0.8919\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9038 - val_loss: 0.2341 - val_accuracy: 0.8919\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.9022 - val_loss: 0.2448 - val_accuracy: 0.8926\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.2178 - accuracy: 0.9039 - val_loss: 0.2360 - val_accuracy: 0.8883\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9062 - val_loss: 0.2333 - val_accuracy: 0.8912\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9032 - val_loss: 0.2319 - val_accuracy: 0.8926\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9057 - val_loss: 0.2391 - val_accuracy: 0.8883\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.9036 - val_loss: 0.2543 - val_accuracy: 0.8826\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.9016 - val_loss: 0.2767 - val_accuracy: 0.8762\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9038 - val_loss: 0.2499 - val_accuracy: 0.8883\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.9018 - val_loss: 0.2783 - val_accuracy: 0.8734\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9055 - val_loss: 0.2296 - val_accuracy: 0.8898\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9030 - val_loss: 0.2334 - val_accuracy: 0.8876\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.9007 - val_loss: 0.2439 - val_accuracy: 0.8933\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9048 - val_loss: 0.2367 - val_accuracy: 0.8905\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.9045 - val_loss: 0.2414 - val_accuracy: 0.8898\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.9013 - val_loss: 0.2355 - val_accuracy: 0.8926\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.9022 - val_loss: 0.2309 - val_accuracy: 0.8912\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2344 - accuracy: 0.8949 - val_loss: 0.2410 - val_accuracy: 0.8848\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.9034 - val_loss: 0.2367 - val_accuracy: 0.8862\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.9029 - val_loss: 0.2313 - val_accuracy: 0.8905\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.9046 - val_loss: 0.2420 - val_accuracy: 0.8933\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.9045 - val_loss: 0.2410 - val_accuracy: 0.8876\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9046 - val_loss: 0.2384 - val_accuracy: 0.8876\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9038 - val_loss: 0.2453 - val_accuracy: 0.8890\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.9052 - val_loss: 0.2350 - val_accuracy: 0.8912\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.9027 - val_loss: 0.2333 - val_accuracy: 0.8919\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.9023 - val_loss: 0.2298 - val_accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 724us/step\n",
      "Test Accuracy (Threshold): 0.9026750142287991\n"
     ]
    }
   ],
   "source": [
    "# Convert true classes to one-hot encoding\n",
    "true_classes_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=6)\n",
    "predicted_classes = model.predict(X_test)\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(np.argmax(predicted_classes, axis=1) == np.argmax(true_classes_one_hot, axis=1))\n",
    "print(\"Test Accuracy (Threshold):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 782us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to compare predicted values and actual validation values\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m comparison_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActual\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(comparison_df)\n",
      "File \u001b[1;32mc:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    763\u001b[0m     )\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Use the loaded model to make predictions on test data\n",
    "predictions = loaded_model.predict(X_test)\n",
    "\n",
    "# Create a DataFrame to compare predicted values and actual validation values\n",
    "comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions.flatten()})\n",
    "print(comparison_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

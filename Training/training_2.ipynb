{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prit4\\AppData\\Local\\Temp\\ipykernel_18864\\291067091.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset.csv\"\n",
    "df = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values removed from the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Remove negative values from the dataset\n",
    "for column in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "    df = df[df[column] >= 0]\n",
    "\n",
    "print('Negative values removed from the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# scaled_features = scaler.fit_transform(df[['month', 'day', 'time', 'humidity', 'tempC']])\n",
    "# print(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month       day      time  humidity  tempC\n",
      "0  0.083333  0.032258  0.000000      0.74   0.36\n",
      "1  0.083333  0.032258  0.041667      0.78   0.36\n",
      "2  0.083333  0.032258  0.083333      0.82   0.34\n",
      "3  0.083333  0.032258  0.125000      0.85   0.34\n",
      "4  0.083333  0.032258  0.166667      0.83   0.34\n"
     ]
    }
   ],
   "source": [
    "scaled_features = pd.DataFrame()\n",
    "scaled_features['month'] = df['month'] / 12\n",
    "scaled_features['day'] = df['day'] / 31\n",
    "scaled_features['time'] = df['time'] / 24\n",
    "scaled_features['humidity'] = df['humidity'] / 100\n",
    "scaled_features['tempC'] = df['tempC'] / 50\n",
    "print(scaled_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_features\n",
    "y = df['fan_speed'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2), input_shape=(5,)),\n",
    "    tf.keras.layers.Dense(100, activation=tf.keras.layers.LeakyReLU(alpha=0.2)),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')  # Softmax activation for multi-class classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 3ms/step - loss: 1.4663 - accuracy: 0.3957 - val_loss: 1.3017 - val_accuracy: 0.4395\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2142 - accuracy: 0.4768 - val_loss: 1.1131 - val_accuracy: 0.5619\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5478 - val_loss: 0.9874 - val_accuracy: 0.6088\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.9568 - accuracy: 0.5938 - val_loss: 0.8967 - val_accuracy: 0.6117\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8782 - accuracy: 0.6268 - val_loss: 0.8252 - val_accuracy: 0.6366\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.8189 - accuracy: 0.6591 - val_loss: 0.7777 - val_accuracy: 0.6728\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7686 - accuracy: 0.6816 - val_loss: 0.7438 - val_accuracy: 0.6743\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.6969 - val_loss: 0.7058 - val_accuracy: 0.6963\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.7134 - val_loss: 0.6762 - val_accuracy: 0.7148\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6746 - accuracy: 0.7244 - val_loss: 0.6401 - val_accuracy: 0.7304\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.7355 - val_loss: 0.6119 - val_accuracy: 0.7319\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7499 - val_loss: 0.5982 - val_accuracy: 0.7262\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.7522 - val_loss: 0.5883 - val_accuracy: 0.7340\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.7661 - val_loss: 0.5706 - val_accuracy: 0.7724\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5748 - accuracy: 0.7773 - val_loss: 0.5480 - val_accuracy: 0.7703\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7822 - val_loss: 0.5522 - val_accuracy: 0.7859\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7870 - val_loss: 0.5248 - val_accuracy: 0.7902\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7943 - val_loss: 0.5170 - val_accuracy: 0.7809\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5267 - accuracy: 0.8032 - val_loss: 0.5101 - val_accuracy: 0.8051\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.8066 - val_loss: 0.5123 - val_accuracy: 0.7966\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.5146 - accuracy: 0.8048 - val_loss: 0.5023 - val_accuracy: 0.8229\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8160 - val_loss: 0.4870 - val_accuracy: 0.8044\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4958 - accuracy: 0.8160 - val_loss: 0.4749 - val_accuracy: 0.8201\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8237 - val_loss: 0.4664 - val_accuracy: 0.8201\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8185 - val_loss: 0.4672 - val_accuracy: 0.8222\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8287 - val_loss: 0.4670 - val_accuracy: 0.8073\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.8329 - val_loss: 0.4534 - val_accuracy: 0.8293\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.8347 - val_loss: 0.4598 - val_accuracy: 0.8122\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.8372 - val_loss: 0.4339 - val_accuracy: 0.8300\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4400 - accuracy: 0.8456 - val_loss: 0.4458 - val_accuracy: 0.8343\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8433 - val_loss: 0.4269 - val_accuracy: 0.8514\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4342 - accuracy: 0.8493 - val_loss: 0.4245 - val_accuracy: 0.8293\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.8447 - val_loss: 0.4245 - val_accuracy: 0.8471\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8504 - val_loss: 0.4118 - val_accuracy: 0.8464\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.8481 - val_loss: 0.4139 - val_accuracy: 0.8428\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4115 - accuracy: 0.8554 - val_loss: 0.4120 - val_accuracy: 0.8371\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8614 - val_loss: 0.4007 - val_accuracy: 0.8528\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.4095 - accuracy: 0.8577 - val_loss: 0.4081 - val_accuracy: 0.8506\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8598 - val_loss: 0.3926 - val_accuracy: 0.8677\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3980 - accuracy: 0.8618 - val_loss: 0.4069 - val_accuracy: 0.8471\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.8614 - val_loss: 0.4062 - val_accuracy: 0.8563\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3959 - accuracy: 0.8587 - val_loss: 0.3786 - val_accuracy: 0.8656\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3890 - accuracy: 0.8655 - val_loss: 0.3809 - val_accuracy: 0.8663\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3809 - accuracy: 0.8655 - val_loss: 0.3756 - val_accuracy: 0.8599\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3831 - accuracy: 0.8680 - val_loss: 0.3746 - val_accuracy: 0.8570\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8726 - val_loss: 0.3696 - val_accuracy: 0.8663\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3720 - accuracy: 0.8723 - val_loss: 0.3704 - val_accuracy: 0.8606\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3704 - accuracy: 0.8755 - val_loss: 0.3657 - val_accuracy: 0.8613\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3714 - accuracy: 0.8708 - val_loss: 0.3659 - val_accuracy: 0.8720\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8682 - val_loss: 0.3589 - val_accuracy: 0.8713\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8778 - val_loss: 0.3602 - val_accuracy: 0.8734\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8753 - val_loss: 0.3536 - val_accuracy: 0.8741\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8701 - val_loss: 0.3501 - val_accuracy: 0.8713\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8780 - val_loss: 0.3582 - val_accuracy: 0.8727\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3572 - accuracy: 0.8748 - val_loss: 0.3538 - val_accuracy: 0.8677\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8762 - val_loss: 0.3771 - val_accuracy: 0.8570\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8712 - val_loss: 0.3436 - val_accuracy: 0.8770\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8707 - val_loss: 0.3509 - val_accuracy: 0.8755\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3429 - accuracy: 0.8837 - val_loss: 0.3336 - val_accuracy: 0.8798\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3415 - accuracy: 0.8771 - val_loss: 0.3648 - val_accuracy: 0.8606\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8799 - val_loss: 0.3339 - val_accuracy: 0.8748\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8783 - val_loss: 0.3385 - val_accuracy: 0.8741\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8753 - val_loss: 0.3408 - val_accuracy: 0.8791\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8806 - val_loss: 0.3245 - val_accuracy: 0.8869\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3251 - accuracy: 0.8849 - val_loss: 0.3225 - val_accuracy: 0.8741\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3272 - accuracy: 0.8808 - val_loss: 0.3225 - val_accuracy: 0.8770\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8861 - val_loss: 0.3263 - val_accuracy: 0.8698\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8748 - val_loss: 0.3136 - val_accuracy: 0.8862\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8833 - val_loss: 0.3116 - val_accuracy: 0.8869\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8842 - val_loss: 0.3106 - val_accuracy: 0.8855\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8801 - val_loss: 0.3272 - val_accuracy: 0.8748\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8851 - val_loss: 0.3029 - val_accuracy: 0.8834\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8799 - val_loss: 0.3250 - val_accuracy: 0.8620\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8893 - val_loss: 0.3157 - val_accuracy: 0.8748\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.3215 - accuracy: 0.8790 - val_loss: 0.3073 - val_accuracy: 0.8805\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2966 - accuracy: 0.8922 - val_loss: 0.3039 - val_accuracy: 0.8890\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2962 - accuracy: 0.8899 - val_loss: 0.2980 - val_accuracy: 0.8862\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8870 - val_loss: 0.2988 - val_accuracy: 0.8805\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2965 - accuracy: 0.8874 - val_loss: 0.3025 - val_accuracy: 0.8883\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2926 - accuracy: 0.8929 - val_loss: 0.2968 - val_accuracy: 0.8869\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2960 - accuracy: 0.8885 - val_loss: 0.3023 - val_accuracy: 0.8834\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8883 - val_loss: 0.3115 - val_accuracy: 0.8770\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8856 - val_loss: 0.2989 - val_accuracy: 0.8883\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8925 - val_loss: 0.2819 - val_accuracy: 0.8869\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8876 - val_loss: 0.2889 - val_accuracy: 0.8855\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2888 - accuracy: 0.8854 - val_loss: 0.2958 - val_accuracy: 0.8848\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8854 - val_loss: 0.2811 - val_accuracy: 0.8919\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2869 - accuracy: 0.8870 - val_loss: 0.2938 - val_accuracy: 0.8798\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2803 - accuracy: 0.8950 - val_loss: 0.2845 - val_accuracy: 0.8869\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2835 - accuracy: 0.8893 - val_loss: 0.3087 - val_accuracy: 0.8791\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8844 - val_loss: 0.3275 - val_accuracy: 0.8698\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8872 - val_loss: 0.2948 - val_accuracy: 0.8834\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8904 - val_loss: 0.2757 - val_accuracy: 0.8876\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8893 - val_loss: 0.2870 - val_accuracy: 0.8855\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8906 - val_loss: 0.2704 - val_accuracy: 0.8962\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2793 - accuracy: 0.8938 - val_loss: 0.2953 - val_accuracy: 0.8627\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8909 - val_loss: 0.2795 - val_accuracy: 0.8755\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2754 - accuracy: 0.8915 - val_loss: 0.2800 - val_accuracy: 0.8883\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8915 - val_loss: 0.3128 - val_accuracy: 0.8727\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.2700 - accuracy: 0.8943 - val_loss: 0.2692 - val_accuracy: 0.8898\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=90, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 803us/step\n",
      "Test Accuracy (Threshold): 0.9015367103016505\n"
     ]
    }
   ],
   "source": [
    "# Convert true classes to one-hot encoding\n",
    "true_classes_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=6)\n",
    "predicted_classes = model.predict(X_test)\n",
    "# print(predicted_classes)\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(np.argmax(predicted_classes, axis=1) == np.argmax(true_classes_one_hot, axis=1))\n",
    "print(\"Test Accuracy (Threshold):\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prit4\\OneDrive\\Desktop\\stuff\\active_Github_repos\\Mini_project\\myenv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

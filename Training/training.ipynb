{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prit4\\AppData\\Local\\Temp\\ipykernel_11384\\3674435951.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# X = df[['month', 'day', 'time','humidity','tempC']]\n",
    "# y = df['fan_speed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month       day      time  humidity  tempC  fan_speed\n",
      "0  0.083333  0.032258  0.000000      0.74   0.36          0\n",
      "1  0.083333  0.032258  0.041667      0.78   0.36          0\n",
      "2  0.083333  0.032258  0.083333      0.82   0.34          0\n",
      "3  0.083333  0.032258  0.125000      0.85   0.34          0\n",
      "4  0.083333  0.032258  0.166667      0.83   0.34          0\n"
     ]
    }
   ],
   "source": [
    "df['month'] /= 12\n",
    "df['day'] /= 31\n",
    "df['time'] /= 24\n",
    "df['humidity'] /= 100\n",
    "df['tempC'] /= 50\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month       day      time  humidity   tempC\n",
      "0  0.006944  0.001041  0.000000    0.0074  0.0072\n",
      "1  0.006944  0.001041  0.001736    0.0078  0.0072\n",
      "2  0.006944  0.001041  0.003472    0.0082  0.0068\n",
      "3  0.006944  0.001041  0.005208    0.0085  0.0068\n",
      "4  0.006944  0.001041  0.006944    0.0083  0.0068\n"
     ]
    }
   ],
   "source": [
    "scaled_df = pd.DataFrame()\n",
    "scaled_df['month'] = df['month'] / 12\n",
    "scaled_df['day'] = df['day'] / 31\n",
    "scaled_df['time'] = df['time'] / 24\n",
    "scaled_df['humidity'] = df['humidity'] / 100\n",
    "scaled_df['tempC'] = df['tempC'] / 50\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaled_df[['month', 'day', 'time','humidity','tempC']]\n",
    "y = df['fan_speed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert features and target variable to PyTorch tensors\n",
    "x_tensor = torch.FloatTensor(x.values)\n",
    "y_tensor = torch.LongTensor(y.values)  # Assuming 'fan_speed' is categorical\n",
    "\n",
    "# Split data into training and testing sets\n",
    "test_size = 0.2\n",
    "random_state = 0\n",
    "x_train_tensor, x_test_tensor, y_train_tensor, y_test_tensor = train_test_split(\n",
    "    x_tensor, y_tensor, test_size=test_size, random_state=random_state\n",
    ")\n",
    "\n",
    "# Create a training dataset\n",
    "training_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "validation_data=TensorDataset(x_test_tensor, y_test_tensor)\n",
    "# Define batch size\n",
    "batch_size = 32  # Adjust as needed\n",
    "\n",
    "# Create a DataLoader for training data\n",
    "training_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "validation_loader  = DataLoader(validation_data, batch_size=batch_size, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class speed_predictor(nn.Module):\n",
    "    def __init__(self, input_features=5, hidden1=50, hidden2=50, output_features=1):\n",
    "        super(speed_predictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, output_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, validation_loader, loss_function):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for inputs, labels in validation_loader:\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = loss_function(outputs.float(), labels.float())\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(validation_loader)\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = speed_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = 5\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.190\n",
      "[2,   100] loss: 0.154\n",
      "[3,   100] loss: 0.167\n",
      "[4,   100] loss: 0.154\n",
      "[5,   100] loss: 0.163\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(number_of_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        loss = loss_function(outputs.float(), labels.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 2000 == 99:  # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validation at the end of each epoch\n",
    "    # validation_loss = validate(model, validation_loader, loss_function)\n",
    "    # print(f'Validation Loss after epoch {epoch + 1}: {validation_loss}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06488332384746727\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in validation_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "model_accuracy = correct / total\n",
    "print(model_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
